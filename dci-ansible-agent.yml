---
# Initial Step:
#
# Schedule a new job giving a specific topic and specifying the remote CI.
# The return of this action contains all the data associated with the job,
# we hence register those data for later consumptions
#
- hosts: localhost
  vars:
    dci_login: '{{ dci_login }}'
    dci_password: '{{ dci_password }}'
  tasks:
    - include: "{{ dci_config_dir }}/hooks/teardown.yml"
    - set_fact:
        metadata:
          experimental: '{{ dci_experimental is defined and dci_experimental }}'
    - name: Schedule a new job
      dci_job:
        topic: '{{ dci_topic }}'
        remoteci: '{{ dci_remoteci }}'
        # to have the ability to bypass the scheduler and use a specific
        # jobdefinition
        jobdefinition_id: "{{ dci_jobdefinition_id|default(None) }}"
      register: job_informations
    - name: Set the metadata
      dci_job:
        id: "{{ job_informations['job_id'] }}"
        metadata: '{{ metadata }}'


# New state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to sync the components the job is relying on.
#
- hosts: localhost
  vars:
    dci_status: 'new'
    dci_comment: 'Creating the local mirrors and synchronizing them'
    components: "{{ job_informations['components'] }}"
    job_id: "{{ job_informations['job_id'] }}"
  tasks:
    - block:
      - name: Ensure Apache is installed
        package:
          name: 'httpd'
          state: 'present'
        become: true
      - name: Ensure Apache is running
        systemd:
          name: 'httpd'
          state: 'started'
        become: true
      - name: Ensure python-firewall is installed
        package:
          name: 'python-firewall'
          state: 'present'
        become: true
      - name: Open port 80 on the firewall
        firewalld:
          zone: public
          service: http
          permanent: true
          state: enabled
        register: result
        failed_when: false
        become: true
      - name: Drop existing repo dir
        file:
          path: '{{ dci_mirror_location }}/dci_repo'
          state: absent
        become: true
      - name: Ensure proper directories are created
        file:
          path: '{{ item }}'
          state: directory
          owner: dci-ansible-agent
          group: dci-ansible-agent
        with_items:
          - '{{ dci_cache_dir }}'
          - '{{ dci_mirror_location }}/dci_repo'
        become: true
      - name: Identify outdated files from the cache
        find:
          path: '{{ dci_cache_dir }}'
          age: '4w'
        register: old_files_found
      - name: Purge old files from the local cache
        file:
          path: '{{ item.path }}'
          state: absent
        with_items: '{{ old_files_found.files }}'
      - name: Retrieve component
        dci_component:
          dest: '{{ dci_cache_dir }}/{{ item["id"] }}.tar'
          id: '{{ item["id"] }}'
        with_items: "{{ components }}"

      - name: Unarchive component
        unarchive:
          src: '{{ dci_cache_dir }}/{{ item["id"] }}.tar'
          dest: '{{ dci_mirror_location }}/dci_repo'
          remote_src: True
        with_items: "{{ components }}"

      - name: Prepare the YUM repo file
        yum_repository:
          name: '{{ item["canonical_project_name"] }}'
          description: '{{ item["canonical_project_name"] }}'
          baseurl: '{{ dci_baseurl }}/dci_repo/{{ item["canonical_project_name"] }}/'
          gpgcheck: no
          file: '{{ dci_mirror_location }}/dci_repo/dci_repo'
        with_items: '{{ job_informations["components"] }}'

      - name: Generating RSA key for stack
        user:
          name: 'dci-ansible-agent'
          generate_ssh_key: 'yes'

      rescue:
      - include: plays/failure.yml


# Pre-run state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to boot (not provision) the undercloud
#
- hosts: localhost
  vars:
    dci_status: 'pre-run'
    dci_comment: 'Spawning the undercloud'
    job_id: "{{ job_informations['job_id'] }}"
  tasks:
    - block:
      - include: '{{ dci_config_dir }}/hooks/pre-run.yml'
      - name: Add undercloud
        add_host:
          name: "undercloud"
          groups: "undercloud"
          ansible_fqdn: "{{ undercloud_ip }}"
          ansible_user: "stack"
          ansible_host: "{{ undercloud_ip }}"
          ansible_password: "{{ undercloud_password| default(None) }}"
        when: undercloud_ip is defined and undercloud_ip

      rescue:
      - include: plays/failure.yml

# Run state
#
# User is free to do whaterver she needs before entering running state.
# Usually this is used to provision both undercloud and the overcloud.
#
- hosts: localhost
  vars:
    dci_status: 'running'
    dci_comment: 'Provision the undercloud and the overcloud'
    job_id: "{{ job_informations['job_id'] }}"
  tasks:
    - block:
      - include: '{{ dci_config_dir }}/hooks/running.yml'
      - name: ensure undercloud host is in Ansible inventory
        fail:
          msg: >
            undercloud should be in the Ansible inventory. If you don`t
            use the undercloud_ip in your settings.yml, you can register it by
            yourself at the end of the running.yml hook
        when: "'undercloud' not in hostvars"
      rescue:
      - include: plays/set_undercloud_authorized_keys.yml
      - include_role:
          name: collect-logs
        delegate_to: undercloud
      - include: plays/failure.yml


- hosts: localhost
  vars:
    dci_status: 'post-run'
    dci_comment: 'add the undercloud node to host list'
  tasks:
    - block:
      - include: plays/set_undercloud_authorized_keys.yml
      rescue:
      - include: plays/failure.yml


# Post-run state
#
# User is free to do whaterver she needs before entering post-run state.
# Usually this is used to run tests, certifications, etc...
#
- name: 'Running tests'
  hosts: 'undercloud'
  vars:
    dci_status: 'post-run'
    rhos_release:
      OSP8: 'liberty'
      OSP9: 'mitaka'
      OSP10: 'newton'
      OSP11: 'ocata'
    openstack_certification_output_format: junit
    openstack_certification_output_filename: cert.junit
    openstack_certification_dest_dir: "{{ local_working_dir }}"
    openstack_certification_results_download: true
    openstack_certification_tempest_conf_path: /home/stack/tempest/etc/tempest.conf
    openstack_certification_tempest_conf_path_is_remote: Yes
    openstack_certification_dest_dir: "{{ local_working_dir }}"
    openstack_certification_tests: "{{ remoteci_rhcert_data['tests']|default(['self_check', 'supportable', 'director']) }}"
    remoteci_data: "{{ hostvars['localhost'].job_informations['remoteci']['data']|default({}) }}"
    remoteci_tempest_data: "{{ remoteci_data['tempest']|default({}) }}"
    remoteci_rhcert_data: "{{ remoteci_data['rhcert']|default({}) }}"
  pre_tasks:
    - block:
      - name: default-overrides.conf is in python-tempestconf wince OSP11
        package:
          name: python-tempestconf
          state: present
        become: true
        when: "dci_topic in ['OSP11']"
      - name: default-overrides.conf is in openstack-tempest on OSP9 and OSP10
        package:
          name: openstack-tempest
          state: present
        become: true
        when: "dci_topic in ['OSP9', 'OSP10']"
      - ini_file:
          path: /etc/tempest/default-overrides.conf
          section: '{{ item.section }}'
          option: '{{ item.option }}'
          value: '{{ item.value }}'
        with_items: "{{ remoteci_tempest_data['default_overrides']|default([]) }}"
        become: true
        when: "dci_topic in ['OSP9', 'OSP10']"
    - name: Set the OpenStack release name
      set_fact:
        release: "{{ rhos_release[dci_topic] }}"
    - name: Copy tempest config overrides
      copy:
        src: tempest-overrides.conf
        dest: ~/tempest-deployer-input.conf
  roles:
    - stackdump
    - tripleo-inventory
    - { role: validate-tempest, tempest_exit_on_failure: False }
    - { role: certification, when: "dci_topic in ['OSP9', 'OSP10', 'OSP11']" }

- name: Collect logs
  hosts: 'undercloud'
  vars:
    dci_status: 'post-run'
    artcl_tar_gz: true
    artcl_gzip_only: false
  roles:
    - collect-logs

- name: 'Upload files'
  hosts: localhost
  vars:
    dci_status: 'post-run'
  tasks:
    - name: Upload stack details
      dci_job:
        id: "{{ job_informations['job_id'] }}"
        configuration: "{{ lookup('file', '~/tripleo-stack-dump.json') }}"
      ignore_errors: True

    # NOTE(dsavinea) : We need to ignore the errors because cert.txt
    # is only present for OSP10 for the moment.
    - name: Upload results
      dci_file:
        path: '{{ item.path }}'
        name: '{{ item.name }}'
        job_id: "{{ job_informations['job_id'] }}"
        mime: '{{ item.mime }}'
      with_items:
        - {'name': 'Tempest', 'path': '/var/lib/dci-ansible-agent/.quickstart/nosetests.xml', 'mime': 'application/junit'}
        - {'name': 'Certification', 'path': '/var/lib/dci-ansible-agent/.quickstart/cert.junit', 'mime': 'application/junit'}
      ignore_errors: yes

    - name: Upload logs
      dci_file:
        path: "/var/lib/dci-ansible-agent/.quickstart/collected_files/{{ item }}.tar.gz"
        name: "{{ item }}.tar.gz"
        job_id: "{{ job_informations['job_id'] }}"
        mime: "application/x-compressed"
      with_items:
        - "undercloud"
#        - "{{ groups['overcloud'] }}"

    - name: Clean result files
      file:
        name: '{{ item }}'
        state: absent
      with_items:
        - "~/nosetests.xml"
        - "~/results.subunit"
        - "~/tempest.html"
        - "~/tripleo-stack-dump.json"
        - "~/cert.txt"


# Success state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to teardown the plateform
#
- hosts: localhost
  vars:
    dci_status: 'success'
  tasks:
    - include: "{{ dci_config_dir }}/hooks/teardown.yml"
