---
# Initial Step:
#
# Schedule a new job giving a specific topic and specifying the remote CI.
# The return of this action contains all the data associated with the job,
# we hence register those data for later consumptions
#
- hosts: localhost
  vars:
    dci_login: '{{ dci_login }}'
    dci_password: '{{ dci_password }}'
  tasks:
    - include: "{{ dci_config_dir }}/teardown.yml"
    - name: Schedule a new job
      dci_job:
        topic: '{{ dci_topic }}'
        remoteci: '{{ dci_remoteci }}'
      register: job_informations


# New state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to sync the components the job is relying on.
#
- hosts: localhost
  vars:
    dci_status: 'new'
    dci_comment: 'Creating the local mirrors and synchronizing them'
    components: "{{ job_informations['components'] }}"
    job_id: "{{ job_informations['job_id'] }}"
  tasks:
    - block:
      - name: Ensure Apache is installed
        package:
          name: 'httpd'
          state: 'present'
        become: true
      - name: Ensure Apache is running
        systemd:
          name: 'httpd'
          state: 'started'
        become: true
      - name: Ensure python-firewall is installed
        package:
          name: 'python-firewall'
          state: 'present'
        become: true
      - name: Open port 80 on the firewall
        firewalld:
          zone: public
          service: http
          permanent: true
          state: enabled
        become: true
      - name: Ensure proper directories are created
        file:
          path: '{{ item }}'
          state: directory
          owner: dci-ansible-agent
          group: dci-ansible-agent
        with_items:
          - '{{ dci_cache_dir }}'
          - '{{ dci_mirror_location }}/dci_repo'
        become: true
      - name: Identify outdated files from the cache
        find:
          path: '{{ dci_cache_dir }}'
          age: '4w'
        register: old_files_found
      - name: Purge old files from the local cache
        file:
          path: '{{ item.path }}'
          state: absent
        with_items: '{{ old_files_found.files }}'
      - name: Retrieve component
        dci_component:
          dest: '{{ dci_cache_dir }}/{{ item["id"] }}.tar'
          id: '{{ item["id"] }}'
        with_items: "{{ components }}"

      - name: Unarchive component
        unarchive:
          src: '{{ dci_cache_dir }}/{{ item["id"] }}.tar'
          dest: '{{ dci_mirror_location }}/dci_repo'
          remote_src: True
        with_items: "{{ components }}"

      - name: Prepare the YUM repo file
        yum_repository:
          name: '{{ item["canonical_project_name"] }}'
          description: '{{ item["canonical_project_name"] }}'
          baseurl: '{{ dci_baseurl }}/dci_repo/{{ item["canonical_project_name"] }}/'
          gpgcheck: no
          file: '{{ dci_mirror_location }}/dci_repo/dci_repo'
        with_items: '{{ job_informations["components"] }}'

      rescue:
      - name: Fail properly
        fail:
          msg: 'Something went wrong with the installation'


# Pre-run state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to boot (not provision) the undercloud
#
- hosts: localhost
  vars:
    dci_status: 'pre-run'
    dci_comment: 'Spawning the undercloud'
    job_id: "{{ job_informations['job_id'] }}"
  tasks:
    - block:
      - include: '{{ dci_config_dir }}/hooks/pre-run.yml'

      rescue:
      - name: Fail properly
        fail:
          msg: 'Something went wrong with the installation'


# Run state
#
# User is free to do whaterver she needs before entering running state.
# Usually this is used to provision both undercloud and the overcloud.
#
- hosts: '{{ undercloud_ip }}'
  user: stack
  become: true
  vars:
    dci_status: 'running'
    dci_comment: 'Provision the undercloud and the overcloud'
    job_id: "{{ job_informations['job_id'] }}"
  tasks:
    - block:
      - include: '{{ dci_config_dir }}/hooks/running.yml'

      rescue:
      - name: Tear me down
        shell: echo 'Tear me down'

      - name: Fail properly
        fail:
          msg: 'Something went wrong with the installation'


# Post-run state
#
# User is free to do whaterver she needs before entering post-run state.
# Usually this is used to run tests, certifications, etc...
#
- hosts: localhost
  vars:
    dci_status: 'post-run'
    dci_comment: 'Running tests'
    job_id: "{{ job_informations['job_id'] }}"
  tasks:
    - block:
       - name: Run tests
         dci_run_tests:
           undercloud_ip: '{{ undercloud_ip }}'
           remoteci: '{{ dci_remoteci }}'
           key_filename: '/var/lib/dci-ansible-agent/.ssh/id_rsa'
           job_id: '{{ job_id }}'
           dci_login: '{{ dci_login }}'
           dci_password: '{{ dci_password }}'
       - name: Upload junit results
         dci_file:
           path: '{{ item.path }}'
           name: '{{ item.name }}'
           mime: 'application/junit'
           job_id: '{{ job_id }}'
         with_items:
           - {'name': 'Rally', 'path': 'rally.xml' }
           - {'name': 'Tempest', 'path': 'tempest.xml' }

      rescue:
      - name: Fail properly
        fail:
          msg: 'Something went wrong with the installation'

# Ideally the above could be replaced with a more generic play like the following
#
#- hosts: UNDERCLOUD.IP
#  become: true
#  user: centos
#  vars:
#    dci_status: 'post-run'
#    dci_comment: 'Running tests'
#    tests: "{{ job_informations['tests'] }}"
#  roles:
#    - { role: ansible-role-certification, when: 'certification' in tests }
#    - { role: ansible-role-tempest, when: 'tempest' in tests }

# Success state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to teardown the plateform
#
- hosts: localhost
  vars:
    dci_status: 'success'
  tasks:
    - include: "{{ dci_config_dir }}/teardown.yml"
