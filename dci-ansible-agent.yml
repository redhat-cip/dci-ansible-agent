---
# Initial Step:
#
# Schedule a new job giving a specific topic and specifying the remote CI.
# The return of this action contains all the data associated with the job,
# we hence register those data for later consumptions
#
- hosts: localhost
  tasks:
    - name: Schedule a new job
      dci_job:
        components: '{{ dci_components|default([]) }}'
        topic: '{{ dci_topic }}'
      register: job_informations
    - set_fact:
        job_id: '{{ hostvars.localhost.job_informations.job_id }}'
        components: '{{ hostvars.localhost.job_informations.components }}'
    - name: Set the metadata
      dci_job:
        id: "{{ job_informations['job_id'] }}"
        metadata: '{{ dci_metadata }}'
      when: dci_metadata is defined and dci_metadata


# New state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to sync the components the job is relying on.
#
- name: 'Creating the local mirrors and synchronizing them'
  hosts: localhost
  vars:
    dci_status: 'new'
  tasks:
    - block:
      - name: Ensure Apache is installed
        package:
          name: 'httpd'
          state: 'present'
        become: true
      - name: Ensure Apache is running
        systemd:
          name: 'httpd'
          state: 'started'
        become: true
      - name: Ensure python-firewall is installed
        package:
          name: 'python-firewall'
          state: 'present'
        become: true
      - name: Open port 80 on the firewall
        firewalld:
          zone: public
          service: http
          permanent: true
          state: enabled
        register: result
        failed_when: false
        become: true
      - name: Drop existing repo dir
        file:
          path: '{{ dci_mirror_location }}/dci_repo'
          state: absent
        become: true
      - name: Ensure proper directories are created
        file:
          path: '{{ item }}'
          state: directory
          owner: '{{ ansible_user_id }}'
          group: '{{ ansible_user_gid }}'
        with_items:
          - '{{ dci_cache_dir }}'
          - '{{ dci_mirror_location }}/dci_repo'
        become: true
      - name: Identify outdated files from the cache
        find:
          path: '{{ dci_cache_dir }}'
          age: '4w'
        register: old_files_found
      - name: Purge old files from the local cache
        file:
          path: '{{ item.path }}'
          state: absent
        with_items: '{{ old_files_found.files }}'
      - name: Retrieve component
        dci_component:
          dest: '{{ dci_cache_dir }}/{{ item["id"] }}.tar'
          id: '{{ item["id"] }}'
        with_items: "{{ components }}"

      - name: Unarchive component
        unarchive:
          src: '{{ dci_cache_dir }}/{{ item["id"] }}.tar'
          dest: '{{ dci_mirror_location }}/dci_repo'
          remote_src: True
        with_items: "{{ components }}"

      - name: Prepare the YUM repo file
        yum_repository:
          name: '{{ item["canonical_project_name"] }}'
          description: '{{ item["canonical_project_name"] }}'
          baseurl: '{{ dci_baseurl }}/dci_repo/{{ item["canonical_project_name"] }}/'
          gpgcheck: no
          file: '{{ dci_mirror_location }}/dci_repo/dci_repo'
        with_items: '{{ job_informations["components"] }}'

      - name: Generating RSA key for stack
        user:
          name: '{{ ansible_user_id }}'
          generate_ssh_key: 'yes'

      rescue:
      - include: plays/failure.yml


# Pre-run state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to boot (not provision) the undercloud
#
- name: 'Spawning the undercloud'
  hosts: localhost
  vars:
    dci_status: 'pre-run'
  tasks:
    - block:
      - include: '{{ dci_config_dir }}/hooks/pre-run.yml'

      rescue:
      - include: "{{ dci_config_dir }}/hooks/teardown.yml"
        when: dci_teardown_on_failure is defined and dci_teardown_on_failure

      - include: plays/failure.yml


# Run state
#
# User is free to do whaterver she needs before entering running state.
# Usually this is used to provision both undercloud and the overcloud.
#
- name: 'Provision the undercloud and the overcloud'
  hosts: localhost
  vars:
    dci_status: 'running'
  tasks:
    - block:
      - include: '{{ dci_config_dir }}/hooks/running.yml'

      - include: plays/register_undercloud_host.yml

      rescue:
      # Included a second time in case of failure in hooks/running.yml,
      # this is required for collect-logs to work
      - include: plays/register_undercloud_host.yml

      - include_role:
          name: "{{ dci_topic }}/collect-logs"
        delegate_to: undercloud
        ignore_errors: True

      - include: "{{ dci_config_dir }}/hooks/teardown.yml"
        when: dci_teardown_on_failure is defined and dci_teardown_on_failure

      - include: plays/failure.yml


- hosts: all:localhost
  vars:
    rhos_release:
      OSP8: 'liberty'
      OSP9: 'mitaka'
      OSP10: 'newton'
      OSP11: 'ocata'
  tasks:
    - name: Declare facts on all hosts
      set_fact:
        job_id: '{{ hostvars.localhost.job_informations.job_id }}'
        components: '{{ hostvars.localhost.job_informations.components }}'
        release: '{{ rhos_release[dci_topic] }}'


# Post-run state
#
# User is free to do whaterver she needs before entering post-run state.
# Usually this is used to run tests, certifications, etc...
#
- name: 'Running tests'
  hosts: 'undercloud'
  vars:
    dci_status: 'post-run'
    remoteci_data: "{{ hostvars['localhost'].job_informations['remoteci']['data']|default({}) }}"
    remoteci_data_rhcert: "{{ remoteci_data['rhcert']|default({}) }}"
    tempest_exit_on_failure: false
    run_tempest: true
    openstack_certification_output_format: junit
    openstack_certification_output_filename: cert.junit
    openstack_certification_dest_dir: "{{ lookup('env', 'HOME') }}/.quickstart"
    openstack_certification_results_download: true
    openstack_certification_tempest_conf_path: /home/stack/tempest/etc/tempest.conf
    openstack_certification_tempest_conf_path_is_remote: Yes
    openstack_certification_tests: "{{ remoteci_data_rhcert['tests']|default(['self_check', 'supportable', 'director']) }}"
  tasks:
    - block:
      - name: default-overrides.conf is in python-tempestconf wince OSP11
        package:
          name: python-tempestconf
          state: present
        become: true
        when: dci_topic in ['OSP11']

      - name: default-overrides.conf is in openstack-tempest on OSP9 and OSP10
        package:
          name: openstack-tempest
          state: present
        become: true
        when: dci_topic in ['OSP9', 'OSP10']

      - ini_file:
          path: /etc/tempest/default-overrides.conf
          section: '{{ item.section }}'
          option: '{{ item.option }}'
          value: '{{ item.value }}'
        with_items: "{{ remoteci_data['tempest']['default_overrides']|default([]) }}"
        become: true
        when: dci_topic in ['OSP9', 'OSP10'] and 'tempest' in remoteci_data.keys()

      - name: Copy tempest config overrides
        copy:
          src: tempest-overrides.conf
          dest: ~/tempest-deployer-input.conf

      - include_role:
          name: "{{ dci_topic }}/validate-tempest"

      - include_role:
          name: "{{ dci_topic }}/tripleo-inventory"

      - include_role:
          name: "openstack-certification"
        when: dci_topic in ['OSP10', 'OSP11']

      rescue:
      - include: "{{ dci_config_dir }}/hooks/teardown.yml"
        when: dci_teardown_on_failure is defined and dci_teardown_on_failure
        delegate_to: localhost

      - include: plays/failure.yml
        delegate_to: localhost


- name: Collect logs
  hosts: 'undercloud'
  vars:
    dci_status: 'post-run'
    artcl_tar_gz: true
    artcl_gzip_only: false
  tasks:
    - block:
      - include_role:
          name: "{{ dci_topic }}/collect-logs"

      rescue:
      - include: "{{ dci_config_dir }}/hooks/teardown.yml"
        when: dci_teardown_on_failure is defined and dci_teardown_on_failure
        delegate_to: localhost

      - include: plays/failure.yml
        delegate_to: localhost


- name: 'Upload files'
  hosts: localhost
  vars:
    dci_status: 'post-run'
  tasks:
    - block:
      #Â NOTE(dsavinea) : We need to ignore the errors because cert.txt
      # is only present for OSP10 for the moment.
      - name: Upload results
        dci_file:
          path: '{{ item.path }}'
          name: '{{ item.name }}'
          job_id: '{{ job_id }}'
          mime: '{{ item.mime }}'
        with_items:
          - {'name': 'Tempest', 'path': "{{ lookup('env', 'HOME') }}/.quickstart/nosetests.xml", 'mime': 'application/junit'}
          - {'name': 'Certification', 'path': "{{ lookup('env', 'HOME') }}/.quickstart/cert.junit", 'mime': 'application/junit'}
          - {'name': 'certification.xml.gz', 'path': "{{ lookup('env', 'HOME') }}/.quickstart/certification.xml.gz", 'mime': 'application/x-compressed'}
          - {'name': 'undercloud.tar.gz', 'path': "{{ lookup('env', 'HOME') }}/.quickstart/collected_files/undercloud.tar.gz", 'mime': 'application/x-compressed'}
        ignore_errors: yes

      - name: Clean result files
        file:
          name: "{{ lookup('env', 'HOME') }}/.quickstart"
          state: absent

      rescue:
      - include: "{{ dci_config_dir }}/hooks/teardown.yml"
        when: dci_teardown_on_failure is defined and dci_teardown_on_failure

      - include: plays/failure.yml


# Success state
#
# User is free to do whaterver she needs before entering pre-run state.
# Usually this is used to teardown the plateform
#
- name: 'Successful installation'
  hosts: localhost
  vars:
    dci_status: 'success'
  tasks:
    - include: "{{ dci_config_dir }}/hooks/success.yml"

    - include: "{{ dci_config_dir }}/hooks/teardown.yml"
